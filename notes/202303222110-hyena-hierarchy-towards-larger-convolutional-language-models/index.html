<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
        <meta content="IE=edge" http-equiv="X-UA-Compatible"/>
        <meta content="text/html; charset=UTF-8" http-equiv="content-type"/>
        <meta content="width=device-width, initial-scale=1" name="viewport"/>

        
        
        

        

        
        
        

        

        
        
        

        <title>Hyena Hierarchy: Towards Larger Convolutional Language Models</title>
        
        <meta name="title" content="Hyena Hierarchy: Towards Larger Convolutional Language Models">
        
        <meta name="description" content="My personal website and notes">
        <meta name="generator" content="Zola v0.16.1">

        <meta property="og:type" content="website">
        <meta property="og:url" content="https://www.thomasantony.com/notes/202303222110-hyena-hierarchy-towards-larger-convolutional-language-models/">
        <meta property="og:site_name" content="thomasantony.com">
        <meta property="og:title" content="Hyena Hierarchy: Towards Larger Convolutional Language Models">
        <meta property="og:description" content="My personal website and notes">
        

        
        
        <meta property="twitter:card" content="summary_large_image">
        <meta property="twitter:url" content="https://www.thomasantony.com/notes/202303222110-hyena-hierarchy-towards-larger-convolutional-language-models/">
        <meta property="twitter:title" content="Hyena Hierarchy: Towards Larger Convolutional Language Models">
        <meta property="twitter:description" content="My personal website and notes">
        
        

        <link rel="canonical" href="https://www.thomasantony.com/notes/202303222110-hyena-hierarchy-towards-larger-convolutional-language-models/">
        
        <script type="application/ld+json">
            {
                "description":"My personal website and notes",
                "url":"https://www.thomasantony.com/notes/202303222110-hyena-hierarchy-towards-larger-convolutional-language-models/",
                "@type":"WebSite",
                "headline":"Hyena Hierarchy: Towards Larger Convolutional Language Models",
                "name":"Hyena Hierarchy: Towards Larger Convolutional Language Models",
                
                "@context":"https://schema.org"
            }
        </script>
        
        
        
        <link rel="alternate" type="application/atom+xml" title="RSS" href="https://www.thomasantony.com/atom.xml">
        
        
        
        <link rel="stylesheet" href="https://www.thomasantony.com/style.css"/>
        

        
            <!-- MathJax configuration -->
            <script src="https://www.thomasantony.com/js/math.js" type="text/javascript"></script>
            <script async defer src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML,Safe"> </script>
        
    </head>
    <body theme="auto">
        <div class="w">
            <header>
                <nav>
                    
                    [
                      
                      <a href="https://www.thomasantony.com">home</a>,
                      <a href="https://www.thomasantony.com/posts">posts</a>,
                      <a href="https://www.thomasantony.com/projects">projects</a>,
                      <a href="https://www.thomasantony.com/notes">notes</a>
                    ]
                    
                </nav>

            </header>
            <main class="page-content" aria-label="Content">
                
<section>
<p id="post">
  <h1>Hyena Hierarchy: Towards Larger Convolutional Language Models</h1>
  <article><p>Here are some rough notes on the “Hyena Hierarchy” architecture described in the paper <a rel="noopener" target="_blank" title="Hyena Hierarchy: Towards Larger Convolutional Language Models" href="https://arxiv.org/abs/2302.10866">1</a>.</p>
<ul>
<li>
<p>This is a new way of getting sub-quadratic scaling for attention</p>
</li>
<li>
<p>it uses convolution filter</p>
<ul>
<li>typical convolution filters are in the form of an array of values which are learned and applied like an Finite-Impulse-Response discrete filter (FIR)<a rel="noopener" target="_blank" title="Finite Impulse Response" href="https://en.wikipedia.org/wiki/Finite_impulse_response">2</a></li>
<li>this doesn’t scale well</li>
<li>instead the filter parameters are represented as a function of “t” where “t” represents the index or “time-step” in the filter. This means you can get a filter of any length from a limited number of parameters</li>
<li>furthermore, this function is chosen to be the output of a state-space model of the type from control theory (Ax+Bu, Cx+Du etc.)</li>
<li>If x0 = 0, then you can get an expression for the output “y” (aka the filter), in terms of matrices A, B, C and D (which can be learned during training)</li>
<li>dimensions of the state-space model and structore of the matrices represent the degrees of freedom available</li>
</ul>
</li>
<li>
<p>FFT can be used to implement convolutions</p>
</li>
<li>
<p>Typical attention involves three linear projections passed through a softmax function - called query, key and value</p>
</li>
<li>
<p>“Hyena” uses N+1 linear projections (not necessarily equal to three). One of these projections take the role of the “value”.</p>
</li>
<li>
<p>So <code>y = H(u)v</code></p>
<ul>
<li>H(u) is defined by “interleaving implicit long convolutions and element-wise multiplication” with one projection at a time</li>
<li>It somehow retains the sublinear scaling by not “materializing” H(u)</li>
<li>The element-wise product in time domain corresponds to convolution in frequency domain</li>
</ul>
</li>
<li>
<p>more details to come as I understand the paper further</p>
</li>
</ul>
<h2 id="references">References</h2>
<p>[<a rel="noopener" target="_blank" title="Hyena Hierarchy: Towards Larger Convolutional Language Models" href="https://arxiv.org/abs/2302.10866">1</a>] “<a rel="noopener" target="_blank" href="https://arxiv.org/abs/2302.10866">Hyena Hierarchy: Towards Larger Convolutional Language Models</a>”, Poli et.al</p>
<p>[<a rel="noopener" target="_blank" title="Finite Impulse Response" href="https://en.wikipedia.org/wiki/Finite_impulse_response">2</a>] <a rel="noopener" target="_blank" href="https://en.wikipedia.org/wiki/Finite_impulse_response">Finite-Impulse Response</a></p>
</article>
</p>
<p>
  <h2>Backlinks</h2>
  
  
  
  
  <li><a href="https:&#x2F;&#x2F;www.thomasantony.com&#x2F;notes&#x2F;ai-ml&#x2F;">AI&#x2F;ML</a></li>
  
  
  <li><a href="https:&#x2F;&#x2F;www.thomasantony.com&#x2F;notes&#x2F;ai-research-papers&#x2F;">AI Research Papers</a></li>
  
  
</p>
</section>



            </main>
            <footer>
                
                
            </footer>
        </div>
    </body>
</html>
